# ManyMusic-stim

We present the ManyMusic-Stim dataset, an open-access music audio dataset designed for human experiments on musical emotions. This is part of the [ManyMusic](https://manymusic.net/) project, which aims to deep-phenotype affective experience evoked by music.

The work is a collaboration between the [Max Planck Institute for Empirical Aesthetics](https://www.aesthetics.mpg.de/en.html) and [Pompeu Fabra University](https://www.upf.edu/web/mtg). Main contributors are [Seung-Goo Kim](https://github.com/seunggookim/), [Pablo Alonso](https://github.com/palonso), and [Dmitry Bogdanov](https://github.com/dbogdanov). Please direct any questions or comments to [Seung-Goo Kim](mailto:seung-goo.kim@ae.mpg.de).

## Related links:
- Intro page: https://manymusic.net/stim/
- Zenodo repo: https://zenodo.org/record/17010882
- Python scripts for curation: https://github.com/manymusic/manymusic-mtg-jamendo-stim-scripts
- Paper: [TBD]
